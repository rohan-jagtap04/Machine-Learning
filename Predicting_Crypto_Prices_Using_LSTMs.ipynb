{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recurrent Neural Network",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMWBW5rAQkWEkkcf3fvbZk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohan-jagtap04/Machine-Learning/blob/main/Predicting_Crypto_Prices_Using_LSTMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4gSkpqHD7vJ",
        "outputId": "91e6d089-3b56-45a6-92a9-7d04cb40ae51"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "from collections import deque\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "\n",
        "\n",
        "SEQ_LEN = 60\n",
        "FUTURE_PERIOD_PREDICT = 3\n",
        "RATIO_TO_PREDICT = \"LTC-USD\"\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "NAME = f\"{RATIO_TO_PREDICT}-{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"\n",
        "\n",
        "def classify(current, future):\n",
        "    if float(future) > float(current):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "    \n",
        "def preprocess_df(df):\n",
        "    df = df.drop('future', 1)\n",
        "    \n",
        "    for col in df.columns:\n",
        "        if col != \"target\":\n",
        "            df[col] = df[col].pct_change()\n",
        "            df.dropna(inplace=True)\n",
        "            df[col] = preprocessing.scale(df[col].values)\n",
        "            \n",
        "    df.dropna(inplace=True)\n",
        "    \n",
        "    sequential_data = []\n",
        "    prev_days = deque(maxlen=SEQ_LEN)\n",
        "    \n",
        "    for i in df.values:\n",
        "        prev_days.append([n for n in i[:-1]])\n",
        "        if len(prev_days) == SEQ_LEN:\n",
        "            sequential_data.append([np.array(prev_days), i[-1]])\n",
        "            \n",
        "    random.shuffle(sequential_data)\n",
        "    \n",
        "    buys = []\n",
        "    sells = []\n",
        "    \n",
        "    for seq, target in sequential_data:\n",
        "        if target == 0:\n",
        "            sells.append([seq, target])\n",
        "        elif target == 1:\n",
        "            buys.append([seq, target])\n",
        "            \n",
        "    random.shuffle(buys)\n",
        "    random.shuffle(sells)\n",
        "    \n",
        "    lower = min(len(buys), len(sells))\n",
        "    \n",
        "    buys = buys[:lower]\n",
        "    sells = sells[:lower]\n",
        "    \n",
        "    sequential_data = buys+sells\n",
        "    random.shuffle(sequential_data)\n",
        "    \n",
        "    X = []\n",
        "    y = []\n",
        "    \n",
        "    for seq, target in sequential_data:\n",
        "        X.append(seq)\n",
        "        y.append(target)\n",
        "    return np.array(X), y\n",
        "\n",
        "main_df = pd.DataFrame()\n",
        "\n",
        "ratios = [\"BTC-USD\", \"LTC-USD\", \"BCH-USD\", \"ETH-USD\"]\n",
        "for ratio in ratios:\n",
        "\n",
        "    ratio = ratio.split('.csv')[0]\n",
        "    print(ratio)\n",
        "    dataset = f'./sample_data/{ratio}.csv'  # get the full path to the file.\n",
        "    df = pd.read_csv(dataset, names=['time', 'low', 'high', 'open', 'close', 'volume'])\n",
        "\n",
        "    df.rename(columns={\"close\":f\"{ratio}_close\", \"volume\":f\"{ratio}_volume\"}, inplace=True)\n",
        "\n",
        "    df.set_index('time', inplace=True)\n",
        "    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]\n",
        "\n",
        "    if len(main_df) == 0:\n",
        "        main_df = df\n",
        "    else:\n",
        "        main_df = main_df.join(df)\n",
        "        \n",
        "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
        "main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))\n",
        "\n",
        "main_df.dropna(inplace=True)\n",
        "\n",
        "times = sorted(main_df.index.values)\n",
        "last_5pct = sorted(main_df.index.values)[-int(0.05*len(times))]\n",
        "\n",
        "validation_main_df = main_df[(main_df.index >= last_5pct)]\n",
        "main_df = main_df[(main_df.index < last_5pct)]\n",
        "\n",
        "train_x, train_y = preprocess_df(main_df)\n",
        "validation_x, validation_y = preprocess_df(validation_main_df)\n",
        "\n",
        "print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n",
        "print(f\"Dont buys: {train_y.count(0)}, buys: {train_y.count(1)}\")\n",
        "print(f\"VALIDATION Dont buys: {validation_y.count(0)}, buys: {validation_y.count(1)}\")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=opt,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=\"C:/logs/{}\".format(NAME))\n",
        "\n",
        "filepath = \"RNN_Final-{epoch:02d}-{val_accuracy:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
        "checkpoint = ModelCheckpoint(\"C:/models/{}.model\".format(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')) # saves only the best ones\n",
        "\n",
        "train_y = np.array(train_y, dtype=np.float32)\n",
        "validation_y = np.array(validation_y, dtype=np.float32)\n",
        "\n",
        "history = model.fit(\n",
        "    train_x, train_y,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(validation_x, validation_y),\n",
        "    callbacks=[tensorboard, checkpoint],\n",
        ")\n",
        "\n",
        "model.save(\"C:/models/{}\".format(NAME))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BTC-USD\n",
            "LTC-USD\n",
            "BCH-USD\n",
            "ETH-USD\n",
            "train data: 68836 validation: 3400\n",
            "Dont buys: 34418, buys: 34418\n",
            "VALIDATION Dont buys: 1700, buys: 1700\n",
            "Epoch 1/10\n",
            "1076/1076 [==============================] - 353s 323ms/step - loss: 0.7483 - accuracy: 0.5120 - val_loss: 0.6868 - val_accuracy: 0.5482\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:/models/RNN_Final-01-0.548.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:/models/RNN_Final-01-0.548.model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/10\n",
            "1076/1076 [==============================] - 345s 321ms/step - loss: 0.6896 - accuracy: 0.5389 - val_loss: 0.6855 - val_accuracy: 0.5506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:/models/RNN_Final-02-0.551.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:/models/RNN_Final-02-0.551.model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/10\n",
            "1076/1076 [==============================] - 346s 322ms/step - loss: 0.6843 - accuracy: 0.5561 - val_loss: 0.6787 - val_accuracy: 0.5641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_18_layer_call_fn, lstm_cell_18_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:/models/RNN_Final-03-0.564.model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:/models/RNN_Final-03-0.564.model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/10\n",
            " 855/1076 [======================>.......] - ETA: 1:10 - loss: 0.6821 - accuracy: 0.5614"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}